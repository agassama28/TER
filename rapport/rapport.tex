\documentclass[a4paper,11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english, french]{babel}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{amsthm}
\geometry{margin=2.5cm}

\theoremstyle{plain}
\newtheorem{thm}{Théorème}

\theoremstyle{definition}
\newtheorem{dfn}{Définition}

\newcommand{\E}{\mathbb{E}}
\newcommand{\Prb}{\mathbb{P}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\sumin}{\sum_{i=1}^n}
\newcommand{\limN}{\xrightarrow[n \to \infty]{}}

\title{Illustrations numériques de la LGN et du TCL}
\author{Abdoulaye GASSAMA \\ Yassine EL JARJINI}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
In this report, we will aim to numerically illustrate two theorems: the Law of Large Numbers and the Central Limit Theorem. We will use Python (with the help of the libraries numpy and matplotlib) to visualize the convergence of the theoretical average.
\end{abstract}

\tableofcontents

\section{Introduction}
introduction

\section{Convergence de variables aléatoires}

\begin{dfn}
On dit que \( X_n \) converge presque sûrement vers \( X \), noté \( X_n \xrightarrow{p.s.} X \), si
\[
\Prb\left( \left\{ \omega \in \Omega \; \middle| \; X_n(\omega) \xrightarrow[n \to \infty]{} X(\omega) \right\} \right) = 1.
\]
\end{dfn}

\begin{dfn}
On dit que \( X_n \) converge vers \( X \) dans \( L^p \), noté \( X_n \xrightarrow{L^p} X \), si
\[
\E\left[ \left| X_n - X \right|^p \right] \xrightarrow[n \to \infty]{} 0.
\]
\end{dfn}

\begin{dfn}
On dit que \( X_n \) converge vers \( X \) en probabilité, noté \( X_n \xrightarrow{\Prb} X \), si pour tout \( \varepsilon > 0 \),
\[
\Prb\left( \left| X_n - X \right| > \varepsilon \right) \xrightarrow[n \to \infty]{} 0.
\]
\end{dfn}

\section{Loi des Grands Nombres}

\begin{thm}[Loi faible des Grands Nombres]
Soit $(X_n)_{n \geq 1}$ une suite de variables aléatoires indépendantes et i.i.d. On suppose que $\mathbb{E}[X_1] = \mu$ et $\Var(X_1) = \sigma^2 < \infty$. Soit
\[
\bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i.
\]
Alors $\bar{X}_n$ converge en probabilité vers $\mu$.
\end{thm}

\begin{proof}
On a : $\E[\bar{X}_n] = \mu$ par linéarité de l'espérance. Par l'inégalité de Bienaymé-Tchebychev, pour tout $\varepsilon > 0$ :
\[
\Prb\left( \left| \bar{X}_n - \mu \right| > \varepsilon \right) \leq \frac{\Var(\bar{X}_n)}{\varepsilon^2}.
\]

Or,
\[
\Var(\bar{X}_n) = \Var\left( \frac{1}{n} \sum_{i=1}^n X_i \right) = \frac{1}{n^2} \sum_{i=1}^n \Var(X_1) = \frac{\sigma^2}{n}.
\]

Donc,
\[
\Prb\left( \left| \bar{X}_n - \mu \right| > \varepsilon \right) \leq \frac{\sigma^2}{n \varepsilon^2} \xrightarrow[n \to \infty]{} 0.
\]

Ce qui conclut la preuve.
\end{proof}

\begin{thm}[Loi forte des Grands Nombres]
Sous les mêmes hypothèses, \(\bar{X}_n\) converge presque sûrement vers \(\mu\).
\end{thm}

\section{Théorème Central Limite}

\begin{thm}[Théorème Central Limite]
Soit $(X_n)_{n \geq 1}$ une suite de variables aléatoires réelles indépendantes et de même loi, dans $L^2$. Soit $\sigma^2 = \Var(X_1)$. Alors,
\[
\frac{1}{\sqrt{n}} \left( X_1 + \cdots + X_n - n\E[X_1] \right) \xrightarrow[n \to \infty]{\mathcal{L}} \mathcal{N}(0, \sigma^2),
\]
où $\mathcal{N}(0, \sigma^2)$ désigne la loi normale centrée de variance $\sigma^2$.
\end{thm}

\section{Illustrations numériques}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figures/figure_lgn_1.png}
\caption{Illustration de la LGN pour la loi normale}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figures/figure_lgn_2.png}
\caption{Illustration de la LGN pour la loi uniforme}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figures/figure_lgn_3.png}
\caption{Illustration de la LGN pour la loi exponentielle}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figures/figure_tcl_1.png}
\caption{Illustration du TCL pour des variables de Bernoulli}
\end{figure}

\section{Conclusion}
...

\begin{thebibliography}{9}
\bibitem{pages2018}
Gilles Pagès, \textit{Numerical Probability: An Introduction with Applications to Finance}, Springer, 2018.

\bibitem{tugaut}
Julian Tugaut, \textit{Les bases indispensables des Probabilités et des Statistiques — Cours et exercices corrigés}, Ellipses, 2020.
\end{thebibliography}

\end{document}
